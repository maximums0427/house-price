install.packages("caret",dependencies = c("Depends","Suggests"))
library(caret)
install.packages(c("lattice", "ggplot2"))
library(caret)
library(lattice)
library(ggplot2)
install.packages("munsell")
library(ggplot2)
library(caret)
install.packages("xgboost")
data("iris")
x<-iris[,1:4]
y<-iris[5]
y<-iris[,5]
scales<-list(x=list(relation="free"),y=list(relation="free"))
featurePlot(x=x,y=y,plot="denity",scales=cales)
featurePlot(x=x,y=y,plot="denity",scales=scales)
featurePlot(x=x,y=y)
featurePlot(x=x,y=y,plot="density",scales=scales)
featurePlot(x=x,y=y,plot="density")
list(relation="free")
featurePlot(x=x,y=y,plot="box")
summary（iris【，1：4】）
summary（iris[,1:4]）
preprocessParams<-preProcess(iris[,1:4],method=c('scale'))
print(preprocessParams)
help(preprocessParams)
help(preprocess)
help(preProcess)
transformed<-predict(preprocessParams, iris[,1:4])
summary(transformed
)
pairs(transformed)
par(mfrow=c(1,4))
for (i in 1:4){hist(iris[,i])}
preprocessParams<-preProcess(iris[,1:4],method=c('center','scale'))
transformed<-predict(preprocessParams, iris[,1:4])
summary(transformed)
apply(transformed,2,sd)
apply(transformed,2,mean)
print(preprocessParams)
preprocessParams<-preProcess(iris[,1:4],method=c('center','scale','pca'))
print(preprocessParams)
preprocessParams<-preProcess(iris,method=c('center','scale','pca'))
print(preprocessParams)
transformed<-predict(preprocessParams, iris)
summary(transformed)
library(klaR)
library(MASS)
library(klaR)
data(iris)
trainIndex<-createDataPartition(iris$Species, p=0.8, list=F)
print(trainIndex)
dataTrain<-iris[trainIndex,]
dataTest<-iris[-trainIndex,]
table(dataTrain[,5])
fit<-NaiveBayes(Species~., data=dataTrain)
result<-predict(fit,dataTest[,1:4])
result
confusionMatrix(result$class,dataTest[,5])
tC <- trainControl(method='cv',number = 10)
fit<-train(Species~., data=iris, trControl=tC, method='nb')
print(fit)
library(mlbench)
library(BostonHousing)
install.packages(BostonHousing)
data(BostonHousing)
head(BostonHousing)
fit<-lm(medv~.,BostonHousing)
predictions<-predict(fit,BostonHousing[,1:13])
mse<-mean((BostonHousing$medv-predictions)^2)
print(mse)
predictions<-predict(fit,BostonHousing)
mse<-mean((BostonHousing$medv-predictions)^2)
print(mse)
library(caret)
set.seed(7)
tC<-trainControl(method='cv',number=5)
fit.lm<-train(medv~,data=BostonHousing,method='lm',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
fit.lm<-train(medv~.,data=BostonHousing,method='lm',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
print(fit.lm)
tC<-trainControl(method='cv',number=1)
fit.lm<-train(medv~.,data=BostonHousing,method='lm',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
tC<-trainControl(method='cv',number=2)
fit.lm<-train(medv~.,data=BostonHousing,method='lm',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
print(fit.lm)
help("train")
tC<-trainControl(method='cv',number=10)
fit.lm<-train(medv~.,data=BostonHousing,method='lm',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
print(fit.lm)
summary(fit.lm)
fit.lm<-train(medv~.,data=BostonHousing,method='penalized',metric='RMSE',preProcess=c('center','scale'), trControl=tC)
print(fit.lm)
data("PimaIndiansDiabetes")
fit<-glm(diabetes~., data=PimaIndiansDiabetes,family=binomial(link='logit'))
print(fit)
prob<-predict(fit,PimaIndiansDiabetes[,1:8],type='response')
predictions<-ifelse(prob>0.5,'pos','neg')
table(predictions, PimaIndiansDiabetes[,9])
help(clean)
help(clear)
tC<-trainControl(method='repeatedcv',number=10,repeats=3)
set.seed(7)
fit.cart <- train(diabetes~., data=PimaIndiansDiabetes, method='rpart',trControl = tC)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method='lda',trControl = tC)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method='svmRadial',trControl = tC)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method='knn',trControl = tC)
fit.rf <- train(diabetes~., data=PimaIndiansDiabetes, method='rf',trControl = tC)
help("resamples")
results<-resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf))
summary(results)
scales<-list(x=list(relation='free'), y=list(relation='free'))
bwplot(results,scales = scales)
results
dotplot(results,scales = scales)
parallelplot(results)
splom(results)
results[,1]
dim(results)
results
summary(results)
xyplot(results, models=c("LDA", "SVM"))
class(result)
class(results)
diffs<-diff(results)
diffs
summary(diffs)
tC<-trainControl(method='repeatedcv',number=10,repeats=3)
set.seed(7)
fit.cart <- train(diabetes~., data=PimaIndiansDiabetes, method='rpart',trControl = tC)
set.seed(7)
fit.lda <- train(diabetes~., data=PimaIndiansDiabetes, method='lda',trControl = tC)
set.seed(7)
fit.svm <- train(diabetes~., data=PimaIndiansDiabetes, method='svmRadial',trControl = tC)
set.seed(7)
fit.knn <- train(diabetes~., data=PimaIndiansDiabetes, method='knn',trControl = tC)
set.seed(7)
fit.rf <- train(diabetes~., data=PimaIndiansDiabetes, method='rf',trControl = tC)
results<-resamples(list(CART=fit.cart, LDA=fit.lda, SVM=fit.svm, KNN=fit.knn, RF=fit.rf))
summary(results)
splom(results)
fit.rf
library(randomForest)
data(Sonar)
head(Sonar)
table(Sonar$Class)
x<-Sonar[,1:60]
y<-Sonar[,61]
ncol(Sonar)
ncol(x)
nrow(x)
sqrt(ncol(x))
floor(sqrt(ncol(x)))
tC<-trainControl(method='repeatedcv',number=10,repeat=3)
tC<-trainControl(method='repeatedcv',number=10,repeats =3)
seed<-7
metric<-"Accuracy"
set.seed(seed)
mtry<-floor(sqrt(ncol(x)))
tunegrid<-expand.grid(.mtry=mtry)
rfDefault<-train(Class~., data=dataset, method='rf', metric=metric, tuneGrid=tunegrid,trControl=tC)
dataset<=Sonar
dataset<-Sonar
rfDefault<-train(Class~., data=dataset, method='rf', metric=metric, tuneGrid=tunegrid,trControl=tC)
print(rfDefault)
tunegrid<-expand.grid(.mtry=11)
rfDefault<-train(Class~., data=dataset, method='rf', metric=metric, tuneGrid=tunegrid,trControl=tC)
print(rfDefault)
tC<-trainControl(method='repeatedcv',number=10,repeats =3, search='grid')
tunegrid<-expand.grid(.mtry=c(1:15))
rfGrid<-train(Class~., data=dataset, method='rf', metric=metric, tuneGrid=tunegrid,trControl=tC)
rfGrid<-train(Class~., data=dataset, method='rf', metric=metric, tuneGrid=tunegrid,trControl=tC)
print(rfGrid)
set.seed(seed)
bestmtry<-tuneRF(x,y,stepFactor = 1.5,improve = 1e-5,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 5,improve = 1e-5,ntreeTry = 500)
bestmtry
bestmtry<-tuneRF(x,y,stepFactor = 1.5,improve = 1e-6,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 1.5,improve = 1e-8,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 1.5,improve = 1e-10,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 1.5,improve = 1e-3,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 5,improve = 1e-5,ntreeTry = 500)
bestmtry<-tuneRF(x,y,stepFactor = 4,improve = 1e-5,ntreeTry = 500)
# Customer Parameter Search
diffs
# Customer Parameter Search
# load the packages
library(randomForest)
library(mlbench)
library(caret)
# configure multi-core (not supported on Windoews)
library(doMC)
registerDoMC(cores=8)
# define the custom caret algorithm (wrapper for Random Forest)
customRF <- list(type="Classification", library="randomForest", loop=NULL)
customRF$parameters <- data.frame(parameter=c("mtry", "ntree"), class=rep("numeric", 2), label=c("mtry", "ntree"))
customRF$grid <- function(x, y, len=NULL, search="grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
randomForest(x, y, mtry=param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc=NULL, submodels=NULL)
predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc=NULL, submodels=NULL)
predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
# Load Dataset
data(Sonar)
dataset <- Sonar
seed <- 7
metric <- "Accuracy"
# train model
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:15), .ntree=c(1000, 1500, 2000, 2500))
set.seed(seed)
custom <- train(Class~., data=dataset, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=trainControl)
install.packages("doMC")
library(mlbench)
library(caret)
library(caretEnsemble)
install.packages("caretEnsemble")
library(caretEnsemble)
data("Ionosphere")
dataset<-Ionosphere
dataset<-dataset[,-2]
head(dataset)
class(dataset$V1)
dataset$V1<-as.numeric(as.character((dataset$V1)))
summary(dataset)
table(dataset$V1)
Ctrl<- trainControl(method='repeatedcv',number=10,repeats=3,savePredictions=T, classProbs=T)
algs<-c('lda','rpart','glm','knn','svmRadial')
set.seed(7)
models<-caretList(Class~., data=dataset, trControl=Ctrl, methodList = algs)
result<-resamples(models)
summary(result)
dotplot(results)
dotplot(result)
modelCor(results)
modelCor(result)
splom(result)
names(getModelInfo())
rm()
rm(*)
ls()
rm(ls())
rm(list(ls())
)
rm(list=ls())
?rm
library(mlbench)
library(caret)
library(caretEnsemble)
library(corrplot)
data("BostonHousing")
dataset<-BostonHousing
head(dataset)
missmap(dataset)
library(Amelia)
install.packages(Amelia)
install.packages("Amelia")
library(Amelia)
missmap(dataset)
dim(dataset)
summary(dataset)
plot(dataset$medv)
plot(dataset$rm,dataset$medv)
cor(dataset)
cor(dataset[,1:])
cor(dataset[,1:14])
class(dataset)
for(i in 1:14){class(dataset[,i])}
for(i in 1:14){print(class(dataset[,i]))}
as.numeric(dataset$chas)
as.integer(dataset$chas)
dataset$chas
?apply
apply(dataset$chas,mean())
apply(dataset$chas,mean
)
apply(dataset$chas,fun = mean)
sapply(dataset$chas,mean)
dataset$chas<-as.numeric(dataset$chas)
cor(dataset)
correlations<-cor(dataset)
corrplot(correlations)
corrplot(correlations,method='circle')
sapply(dataset,class)
data("BostonHousing")
dataset<-BostonHousing
dataset$chas<-as.numeric(as.character(dataset$chas))
dataset$chas
cor(dataset)
par(mfrow=c(2,7))
for (i in 1:13){hist(dataset[,i], main=names(dataset)[i])}
for (i in 1:13){plot(dataset[,i],dataset$medv)}
pairs(dataset)
dataset$chas<-as.numeric(as.character(dataset$chas))
cor(dataset)
set.seed(7)
validationIndex<-createDataPartition(BostonHousing$medv, p=0.8,list=F)
trainset<-dataset[validationIndex,]
testset<-dataset[-validationIndex]
Ctril<-trainControl(method='repeatedcv',number=10,repeats=3)
benchmark<-train(medv~.,data=trainset,method='rf',metric='RMSE', trControl=Ctrl)
Ctrl<-trainControl(method='repeatedcv',number=10,repeats=3)
benchmark<-train(medv~.,data=trainset,method='rf',metric='RMSE', trControl=Ctrl)
summary(benchmark)
benchmark
result<-resamples(list(RF=benckmark))
result<-resamples(list(RF=benchmark))
set.seed(7)
benchmark_std<-train(medv~.,data=trainset,method='rf',metric='RMSE', preProc = c('center','scale','BoxCox'),trControl=Ctrl)
summary(benchmark_std)
benchmark_std
modellist<-list()
Ctrl = trainControl(method='repeatedcv',number=10,repeats=3, search = 'grid')
for (ntree in c(1000,1500,2000,2500)){
set.seed(7)
fit <- train(medv~.,data=trainset,method='rf',metric='RMSE',trControl=Ctrl,ntree=ntree)
key<-toString(ntree)
modellist[[key]]<-fit
}
summary(modellist)
summary(resamples(modellist))
dotplot(resamples(modellist))
Ctrl<-trainControl(method='repeatedcv',number=10,repeats=3)
set.seed(7)
benchmark<-train(medv~.,data=trainset,method='rf',metric='RMSE', trControl=Ctrl,ntree=2000)
benchmark
set.seed(7)
benchmark_CUB<-train(medv~.,data=trainset,method='cubist',metric='RMSE', preProc=c('BoxCox'),trControl=Ctrl)
benchmark_CUB
x<-dataset[,1:13]
y<-dataset[,14]
preprocessParams<-preProcess(x, method=c('BoxCox'))
transX<-predict(preprocessParams,x)
finalModel<-cubist(x=transX,y=y, committees=18)
summary(finalModel)
finalModel
x
preprocessParams<-preProcess(x,method=c('center','scale','pca'))
print(preprocessParams)
transformed<-predict(preprocessParams,x)
summary(transformed)
head(transformed)
transformed$medv = dataset$medv
transformed$medv <- dataset$medv
head(transformed)
set.seed(7)
benchmark_CUB<-train(medv~.,data=trainset,method='cubist',metric='RMSE', preProc=c('BoxCox'),trControl=Ctrl)
benchmark_CUB
set.seed(7)
benchmark_CUB1<-train(medv~.,data=trainset,method='cubist',metric='RMSE', preProc=c('BoxCox'),trControl=Ctrl)
benchmark_CUB1
set.seed(7)
benchmark_CUB1<-train(medv~.,data=transformed,method='cubist',metric='RMSE', preProc=c('BoxCox'),trControl=Ctrl)
benchmark_CUB1
data(iris)
iris.na <- iris
set.seed(111)
## artificially drop some data values.
for (i in 1:4) iris.na[sample(150, sample(20)), i] <- NA
missmap(iris)
iria
iris
missmap(iris.na)
set.seed(222)
iris.imputed <- rfImpute(Species ~ ., iris.na)
iris.imputed
missmap(iris.imputed)
test.filename<-'/data/test.csv'
dataset.test <- read.csv(test.filename, header=F)
ls()
list.files()
list.files()
setwd("C:\Users\maxwa\Documents\GitHub\house-price")
setwd("C:/Users/maxwa/Documents/GitHub/house-price")
list.files()
test.filename<-'/data/test.csv'
dataset.test <- read.csv(test.filename, header=F)
test.filename<-'data/test.csv'
dataset.test <- read.csv(test.filename, header=F)
head(dataset.test)
dataset.test <- read.csv(test.filename)
head(dataset.test)
test.filename<-'data/test.csv'
train.filename<-'data/train.csv'
dataset.test <- read.csv(test.filename)
dataset.train <- read.csv(train.filename)
library(caret)
library(Amelia)
missmap(dataset.train)
table(dataset.train$MiscFeature)
dataset.whole <- rbind(dataset.train, dataset.test)
dataset.whole <- rbind(dataset.train[,1:80], dataset.test)
missmap(dataset.whole)
table(dataset.whole$PoolQC)
View(dataset.train)
sapply(dataset.whole, is.na())
sum(is.na(dataset.whole[,1]))
colname(dataset.train)
colnames(dataset.train)
for( i in 1:80){if(sum(is.na(dataset.whole[,i]))>0){print(colnames(dataset.train)[i])}}
for( i in 1:80){
if(sum(is.na(dataset.whole[,i]))>0){
print(colnames(dataset.train)[i],sum(is.na(dataset.whole[,i]))
}
}
for( i in 1:80){
if(sum(is.na(dataset.whole[,i]))>0){
print(colnames(dataset.train)[i])
print(sum(is.na(dataset.whole[,i])))
}
}
table(dataset.whole$Fence)
library(corrplot)
corrplot(cor(dataset.whole))
corrplot(cor(dataset.whole[,2:80]))
sapply(dataset.whole,class)
